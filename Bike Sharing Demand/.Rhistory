require(lubridate)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links<-xpathSApply(PARSED, "//div[@class='searchresults']//a/@href")
lenght(links)
length(links)
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links<-xpathSApply(PARSED, "//div[@class='search-results results']//a/@href")
links<-xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href')
length(links)
length(unique(links))
links<-unique(links)
getBBCLinks <- function(url){
raw <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-unique(xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href'))
return (links)
}
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
links
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
(xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue))
(xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue)
(xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue))
(xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
url <- "http://www.bbc.co.uk/news/world-europe-26333587"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
require(lubridate)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links
links<-xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href')
length(links)
links
length(unique(links))
links<-unique(links)
getBBCLinks <- function(url){
raw <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-unique(xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href'))
return (links)
}
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
links
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-body_h1']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
(xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue))
(xpathSApply(PARSED, "//span[@class='date']",xmlValue))
headline <- xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue)
date <- xpathSApply(PARSED, "//span[@class='date']",xmlValue)
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
headline <- xpathSApply(PARSED, "//h1[@class='story-header']",xmlValue)
date <- xpathSApply(PARSED, "//span[@class='date']",xmlValue)
(xpathSApply(PARSED, "//h1[@class='story-body__h1']",xmlValue))
(xpathSApply(PARSED, "//time[@itemprop='datePublished']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date-datadaytime']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date-datedaytime']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date-date--v1']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v1']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v1, data--datetime']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2 data--datetime']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2']",xmlValue))
bbcScraper <- function(url){
date=''
title=''
SOURCE <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(SOURCE)
title=xpathSApply(PARSED, "//title",xmlValue)
date=xpathSApply(PARSED, "//meta[@name='OriginalPublicationDate']/@content")
d=data.frame(url,title,date)
return(d)
}
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
dat <- ldply(links,bbcScraper)
SOURCE <-  getURL('http://www.bbc.co.uk/search?q=obama',encoding="UTF-8")
PARSED <- htmlParse(SOURCE)
title=xpathSApply(PARSED, "//title",xmlValue)
date=xpathSApply(PARSED, "//meta[@name='OriginalPublicationDate']/@content")
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
dat <- ldply(links,bbcScraper)
#MIRROR
url <- "http://www.mirror.co.uk/news/world-news/oscar-pistorius-trial-murder-reeva-3181393"
SOURCE <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(SOURCE)
title <- xpathSApply(PARSED, "//h1",xmlValue)
author <- xpathSApply(PARSED, "//li[@class='author']",xmlValue)
time  <- xpathSApply(PARSED, "//time[@itemprop='datePublished']/@datetime")
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-body__h1']",xmlValue))
(xpathSApply(PARSED,"//mini-info-list__item[@class='date date--v2']/@data-datetime"))
(xpathSApply(PARSED,"//mini-info-list__item[@class='date date--v2']/@data-datetime"))
date=xpathSApply(PARSED,"//li[@class='mini-info-list__item']/@data-datetime")
(xpathSApply(PARSED,"//li[@class='mini-info-list__item']/@data-datetime"))
(xpathSApply(PARSED, "//div[@class='date date--v2']",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime",xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime"))
(xpathSApply(PARSED, "//div[@class='date date--v2']/@datetime"))
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime"))
(xpathSApply(PARSED, "//mini-info-list__item[@class='date date--v2']/@data-datetime"))
date=xpathSApply(PARSED,"//div[@class='date date--v2']/@data-datetime")
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime"))
date=xpathSApply(PARSED,"//li[@class='mini-info-list__item]/@div[@class='date date--v2']/@data-datetime")
date=xpathSApply(PARSED,"//li[@class='mini-info-list__item]/@class='date date--v2']/@data-datetime")
date=xpathSApply(PARSED,"//li[@class='mini-info-list__item]/@data-datetime")
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime"))
(xpathSApply(PARSED, '//span[@class='date'))
(xpathSApply(PARSED, "//span[@class='date']", xmlValue))
(xpathSApply(PARSED, "//span[@class='date']", xmlValue))
(xpathSApply(PARSED, "//div[@class='date date--v2']/@data-datetime"))
library(rvest)
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
require(lubridate)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
library(rvest)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links
links<-xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href')
length(links)
#Function to get links
getBBCLinks <- function(url){
raw <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-unique(xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href'))
return (links)
}
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
links
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-body__h1']",xmlValue))
date <- html(url) %>%
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
install.packages("rvest")
install.packages("rvest")
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
install.packages("dplyr")
library(dplyr)
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
require(lubridate)
require(plyr)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
library(dplyr)
library(rvest)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links
links<-xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href')
length(links)
length(unique(links))
links<-unique(links)
#Function to get links
getBBCLinks <- function(url){
getBBCLinks <- function(url){
raw <-  getURL(url,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-unique(xpathSApply(PARSED, '//ol[@class="search-results results"]//a/@href'))
return (links)
}
url='http://www.bbc.co.uk/search?q=obama'
links <-getBBCLinks(url)
links
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-body__h1']",xmlValue))
url <- "http://www.bbc.com/news/world-us-canada-34111860"
SOURCE <-  getURL(url,encoding="UTF-8") # Specify encoding when dealing with non-latin characters
PARSED <- htmlParse(SOURCE)
(xpathSApply(PARSED, "//h1[@class='story-body__h1']",xmlValue))
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
date
date
date <- html(url) %>%
html_node(".mini-info-list__item .date--v2") %>%
html_text()
date
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
require(lubridate)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
library(dplyr)
library(rvest)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links
require(lubridate)
require(plyr)
require(stringr)
require(XML)
require(RCurl)
library(dplyr)
library(rvest)
url <- 'http://www.bbc.co.uk/search?q=obama&filter=news&suggid='
raw <-  getURL(url)#,encoding="UTF-8")
PARSED <- htmlParse(raw) #Format the html code d
links<-xpathSApply(PARSED, "//a/@href")
length(links)
links
getwd()
?randomforest
?random forest
getwd()
setwd('/Users/tommyly/Documents/MySlideRule/MySlideRule-Data-Science-Foundation/Bike Sharing Demand')
getwd()
bike_train = read.csv("train.csv")
bike_test = read.csv("test.csv")
bike_test[c('casual', 'registered', 'count')] = 0 #reformat data so both are the same
bike_total = rbind(bike_train,bike_test) #cannot combine
str(bike_train)
str(bike_test)
str(bike_total)
summary(bike_train)
table(is.na(bike_train)) #No N.A value. Awesome!
bike_train$count
# Finding the index of the time with highest rental
which.max(bike_train$count)
#Get name of all variables in dataset
names(bike_train)
## Get datetime/season/holiday/weather of the highest rental period
bike_train$datetime[9346]
bike_train$season[9346]
bike_train$holiday[9346]
bike_train$weather[9346]
layout(matrix(c(1,1,2,3,4,5),2,3,byrow=FALSE)) #
boxplot(bike_train$count, main="count")
boxplot(bike_train$count ~ bike_train$weather, main="weather")
boxplot(bike_train$count ~ bike_train$season, main="season")
boxplot(bike_train$count ~ bike_train$holiday, main="holiday")
boxplot(bike_train$count ~ bike_train$workingday, main="working day")
#by numerical variable
par(mfrow=c(2,2))
par(mar = rep(2, 4))
hist(bike_train$humidity, main = "humidity")
hist(bike_train$temp, main = "temperature")
hist(bike_train$atemp, main = "feel temperature")
#Bivariate correlation
sub=data.frame(bike_train$registered,bike_train$casual,bike_train$count,bike_train$temp,bike_train$humidity,bike_train$atemp,bike_train$windspeed)
cor(sub)
```
bike_train$season <- factor(bike_train$season, c(1,2,3,4), ordered=FALSE)
bike_train$holiday <- factor(bike_train$holiday, c(0,1), ordered=FALSE)
bike_train$workingday <- factor(bike_train$workingday, c(0,1), ordered=FALSE)
bike_train$weather <- factor(bike_train$weather, c(4,3,2,1), ordered=TRUE)
# set datetime ####
bike_train$datetime <- as.POSIXct(bike_train$datetime, format="%Y-%m-%d %H:%M:%S")
str(bike_train) #check if categorical have switched to factorial data
bike_test$season <- factor(bike_test$season, c(1,2,3,4), ordered=FALSE)
bike_test$holiday <- factor(bike_test$holiday, c(0,1), ordered=FALSE)
bike_test$workingday <- factor(bike_test$workingday, c(0,1), ordered=FALSE)
bike_test$weather <- factor(bike_test$weather, c(4,3,2,1), ordered=TRUE)
# set datetime ####
bike_test$datetime <- as.POSIXct(bike_test$datetime, format="%Y-%m-%d %H:%M:%S")
str(bike_test) #check if categorical have switched to factorial data
```
# 4.1 Feature Engineering
```{r,echo=FALSE}
#create time column by substring out timestamp
bike_train$time <- substring(bike_train$datetime,12,20)
bike_test$time <- substring(bike_test$datetime,12,20)
str(bike_train)
#create day of week column
bike_train$day <- weekdays(as.Date(bike_train$datetime))
bike_train$day <- as.factor(bike_train$day)
bike_test$day <- weekdays(as.Date(bike_test$datetime))
bike_test$day <- as.factor(bike_test$day)
str(bike_train)
#create Sunday variable
bike_train$sunday[bike_train$day == "Sunday"] <- "1"
bike_train$sunday[bike_train$day != "1"] <- "0"
bike_test$sunday[bike_test$day == "Sunday"] <- "1"
bike_test$sunday[bike_test$day != "1"] <- "0"
#convert to factor
bike_train$sunday <- as.factor(bike_train$sunday)
bike_test$sunday <- as.factor(bike_test$sunday)
str(bike_train)
#convert time and create $hour as integer to evaluate for daypart
bike_train$hour<- as.numeric(substr(bike_train$time,1,2))
bike_test$hour<- as.numeric(substr(bike_test$time,1,2))
#create daypart column, default to 4 to make things easier for ourselves
bike_train$daypart <- "4"
bike_test$daypart <- "4"
#4AM - 10AM = 1
bike_train$time <- substring(bike_train$datetime,12,20)
bike_test$time <- substring(bike_test$datetime,12,20)
str(bike_train)
bike_train$day <- weekdays(as.Date(bike_train$datetime))
bike_train$day <- as.factor(bike_train$day)
bike_test$day <- weekdays(as.Date(bike_test$datetime))
bike_test$day <- as.factor(bike_test$day)
str(bike_train)
bike_train$sunday[bike_train$day == "Sunday"] <- "1"
bike_train$sunday[bike_train$day != "1"] <- "0"
bike_train$sunday[bike_train$day == "Sunday"] <- 1
bike_train$sunday[bike_train$day != "1"] <- "0"
bike_test$sunday[bike_test$day == "Sunday"] <- "1"
bike_test$sunday[bike_test$day != "1"] <- "0"
bike_train$sunday <- as.factor(bike_train$sunday)
bike_test$sunday <- as.factor(bike_test$sunday)
str(bike_train)
bike_train$hour<- as.numeric(substr(bike_train$time,1,2))
bike_test$hour<- as.numeric(substr(bike_test$time,1,2))
bike_train$daypart <- "4"
bike_test$daypart <- "4"
bike_train$daypart[(bike_train$hour < 10) & (bike_train$hour > 3)] <- 1
bike_test$daypart[(bike_test$hour < 10) & (bike_test$hour > 3)] <- 1
bike_train$daypart[(bike_train$hour < 16) & (bike_train$hour > 9)] <- 2
bike_test$daypart[(bike_test$hour < 16) & (bike_test$hour > 9)] <- 2
bike_train$daypart[(bike_train$hour < 22) & (bike_train$hour > 15)] <- 3
bike_test$daypart[(bike_test$hour < 22) & (bike_test$hour > 15)] <- 3
bike_train$daypart <- as.factor(bike_train$daypart)
bike_test$daypart <- as.factor(bike_test$daypart)
bike_train$hour <- as.factor(bike_train$hour)
bike_test$hour <- as.factor(bike_test$hour)
install.packages("rpart")
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
library(caTools)
set.seed(3000)
spl = sample.split(bike_train$count, SplitRatio = 0.7)
Train = subset(bike_train, spl==TRUE)
Test = subset(bike_train, spl==FALSE)
Train$casual_log10=log10(Train$casual+1)
Train$registered_log10=log10(Train$registered+1)
BikeForest_Registered = randomForest(registered_log10 ~ season + weather + temp + humidity +
windspeed + hour + sunday + daypart + sunday +
holiday + workingday,data=Train[,-c(10)])
install.packages('randomForest')
library(randomForest)
BikeForest_Registered = randomForest(registered_log10 ~ season + weather + temp + humidity +
windspeed + hour + sunday + daypart + sunday +
holiday + workingday,data=Train[,-c(10)])
BikeForest_Casual = randomForest(casual_log10 ~ season + weather + temp + humidity +
windspeed + hour + sunday + daypart + sunday +
holiday + workingday,data=Train[,-c(11)])
PredictForest_Registered = predict(BikeForest_Registered, newdata = Test)
PredictForest_Casual = predict(BikeForest_Casual, newdata = Test)
PredictForest_Combine <- round(10^PredictForest_Registered + 10^PredictForest_Casual -2)
#Create evaluation function
RMSLE_Evaluation <- function (data, pred) {
return(sqrt(1/nrow(data)*sum((log(pred+1)-log(data$count+1))^2)))}
RMSLE_Evaluation(Test,PredictForest_Combine)
BikeForest_Registered = randomForest(registered_log10 ~ season + weather + temp + humidity + windspeed + hour + sunday + daypart + sunday + holiday + workingday,data=Train[,-c(10)], ntree=250)
BikeForest_Casual = randomForest(casual_log10 ~ season + weather + temp + humidity +
windspeed + hour + sunday + daypart + sunday + holiday + workingday,data=Train[,-c(11)], ntree=250)
PredictForest_Registered = predict(BikeForest_Registered, newdata = Test)
PredictForest_Casual = predict(BikeForest_Casual, newdata = Test)
PredictForest_Combine <- round(10^PredictForest_Registered + 10^PredictForest_Casual -2)
RMSLE_Evaluation(Test,PredictForest_Combine)
PredictForest_Registered_Bike_Test = predict(BikeForest_Registered, newdata = bike_test)
PredictForest_Casual_Bike_Test = predict(BikeForest_Casual, newdata = bike_test)
PredictForest_Combine_Bike_Test <- round(10^PredictForest_Registered + 10^PredictForest_Casual -2)
RMSLE_Evaluation(bike_test,PredictForest_Combine)
RMSLE_Evaluation(bike_test,PredictForest_Combine_Bike_Test)
RMSLE_Evaluation(bike_test,PredictForest_Combine_Bike_Test) -1
RMSLE_Evaluation(bike_test,PredictForest_Combine_Bike_Test) -10
RMSLE_Evaluation(bike_test,PredictForest_Combine_Bike_Test)/10
RMSLE_Evaluation(Test,PredictForest_Combine)
RMSLE_Evaluation(Test,PredictForest_Casual)
RMSLE_Evaluation(Test,PredictForest_Registerd)
RMSLE_Evaluation(Test,round(10^PredictForest_Casual)-1)
RMSLE_Evaluation(Test,round(10^PredictForest_Registerd)-1
RMSLE_Evaluation(Test,round(10^PredictForest_Registerd)-1)
RMSLE_Evaluation(Test,round(10^PredictForest_Registerd)-1)
RMSLE_Evaluation(Test,round(10^PredictForest_Casual)-1)
RMSLE_Evaluation(Test,PredictForest_Combine)
RMSLE_Evaluation(Test,round(10^PredictForest_Casual-1))
RMSLE_Evaluation(Test,round(10^PredictForest_Registerd-1))
RMSLE_Evaluation(Test,round(10^PredictForest_Registerd-1))
RMSLE_Evaluation(Test,round(10^PredictForest_Registered-1))
RMSLE_Evaluation(Test,PredictForest_Combine)
setwd('/Users/tommyly/Documents/MySlideRule/Data Science Foundation/Bike Sharing Demand')
getwd()
bike_train = read.csv("train.csv")
bike_test = read.csv("test.csv")
bike_train = read.csv("data/train.csv")
layout(matrix(c(1,1,2,3,4,5),2,3,byrow=FALSE)) #
boxplot(bike_train$count, main="count")
boxplot(bike_train$count ~ bike_train$weather, main="weather")
boxplot(bike_train$count ~ bike_train$season, main="season")
boxplot(bike_train$count ~ bike_train$holiday, main="holiday")
boxplot(bike_train$count ~ bike_train$workingday, main="working day")
par(mfrow=c(2,2))
par(mar = rep(2, 4))
hist(bike_train$humidity, main = "humidity")
hist(bike_train$temp, main = "temperature")
hist(bike_train$atemp, main = "feel temperature")
